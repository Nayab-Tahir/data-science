{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a87b5ef",
   "metadata": {},
   "source": [
    "---   \n",
    " <img align=\"left\" width=\"75\" height=\"75\"  src=\"https://upload.wikimedia.org/wikipedia/en/c/c8/University_of_the_Punjab_logo.png\"> \n",
    "\n",
    "<h1 align=\"center\">Department of Data Science</h1>\n",
    "<h1 align=\"center\">Course: Tools and Techniques for Data Science</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Instructor: Muhammad Arif Butt, Ph.D.</div></h3>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0dc25c",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lecture 3.16 (Pandas-08)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f82705",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" height=\"400\"  src=\"images/pandas-apps.png\"  >\n",
    "\n",
    "## _Handling Missing Data.ipynb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68517bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6f82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12db95e1",
   "metadata": {},
   "source": [
    "## Learning agenda of this notebook\n",
    "\n",
    "1. Have an insight about the Dataset\n",
    "2. Identify the Columns having Null/Missing values\n",
    "3. Handle/Impute the Null/Missing Values under the `math` Column using `df.loc[mask,col]=value`\n",
    "4. Handle/Impute the Null/Missing Values under the `group` Column using `df.loc[mask,col]=value`\n",
    "5. Handle Missing values under a Numeric/Categorical Column using `fillna()`\n",
    "6. Handle Repeating Values (for same information) under the `session` Column\n",
    "7. Create a new Column by Modifying an Existing Column\n",
    "8. Delete Rows Having NaN values using `df.dropna()` method\n",
    "9. Convert Categorical Variables into Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d059853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab685b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44677ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd54c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8520194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d2bba7a",
   "metadata": {},
   "source": [
    "## 1. Have an Insight about the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/group-marks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7144b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas library\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8653443c",
   "metadata": {},
   "source": [
    "- Whenever the **`pd.read.csv()`** method detects a missing value (nothing between two commas in a csv file or an empty cell in Excel) it flags it with NaN. There can be many reasons for these NaN values, one can be that the data is gathered via google form from people and this field might be optional and skipped.\n",
    "- There can also be a scenario that a user has entered some text under a numeric field about which he/she do not have any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff7541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5439a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78d83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750dd41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43cfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75660b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e15ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2505bd5",
   "metadata": {},
   "source": [
    "## 2. Identify the Columns having Null/Missing values\n",
    "- The **`df.isna()`** method isrecommended to use than `df.isnull()`, which return a boolean same-sized object that indicates whether an element is NA value or not. Missing values get mapped to True. Everything else gets mapped to False values. Remember, characters such as empty strings ``''`` or `numpy.inf` are not considered NA values.\n",
    "- The **`df.notna()`** method is recommended to use than `df.notnull()` methods return a boolean same-sized object that indicates whether an element is NA value or not. Non-missing values get mapped to True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ed31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af437830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use sum() on this dataframe object of Boolean values (True is mapped to 1)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, we can use sum() on this dataframe object of Boolean values (True is is mapped to 1)\n",
    "df.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b18d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d686d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ce087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86209c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14dd039f",
   "metadata": {},
   "source": [
    "## 3. Handle/Impute the Null/Missing Values under the `math` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190177e8",
   "metadata": {},
   "source": [
    "### a. Identify the Rows under the `math` Column having Null/Missing values\n",
    "- The `df.isna()` method works equally good on Series objects as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0853c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.math.isna()\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e2cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a967c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return only those rows of dataframe having null values under the math column\n",
    "df[mask]         # df[df.math.isna()]\n",
    "df.loc[mask, :]  # df.loc[df.math.isna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383ffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ea592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40385f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9efa10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8298b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "430a2bed",
   "metadata": {},
   "source": [
    "### b. Replace the Null/Missing Values under the `math` Column\n",
    "- After detecting the NaN values, the next question is, what value we should write in the cells where we have Null/Missing values under the `math` column\n",
    "- Suppose, we want to put the average values at the place of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8046ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of math column\n",
    "df.math.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f8a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499948af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592607c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baf74d82",
   "metadata": {},
   "source": [
    "> By seeing the error, it appears that the `math` column do not have the `int64` or `float64` type. Let us check this out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13768098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the data type of math column\n",
    "df['math'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the `df.info()` method to display the count of Non-Null columns, their datatypes, their names \n",
    "# and memory usage of that dataframe.\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47274c63",
   "metadata": {},
   "source": [
    "- **What can be the reason for this?**\n",
    "- Let us check out the values under this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can replace all such values using the `replace()` method\n",
    "import numpy as np\n",
    "df.replace('No Idea', np.nan).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589b8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e613d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the marks of Saadia in math are changed from string `No Idea` to `NaN`\n",
    "# Since this seems working fine let us make inplace=True to make these changes in the original dataframe\n",
    "df.replace('No Idea', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93130c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a4557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8991d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the data type of math column\n",
    "df['math'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bed394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc640d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25691869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is still Object, which is natural, however, we can change the datatype to `df.astype()` method\n",
    "df['math'] = df['math'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960b453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411d6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e506ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the data type of math column\n",
    "df['math'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ebf2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928f2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ca38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute the average of math marks again \n",
    "df.math.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b007bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df22e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only those records under math column having Null values\n",
    "mask = df.math.isna()\n",
    "df.loc[mask, 'math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us replace these values with mean value of the math column\n",
    "df.loc[(df.math.isna()),'math'] = df.math.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8abade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec83734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89cde28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f790bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2b18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0989110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9c913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70ac58bc",
   "metadata": {},
   "source": [
    "## 4. Handle/Impute the Null/Missing Values under the `group` Column\n",
    "- The `group` column contains categorical values, i.e., a value that can take on one of a limited, and usually fixed, number of possible values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ebb9ae",
   "metadata": {},
   "source": [
    "### a. Identify the Rows under the `group` Column having Null/Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e93928",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.group.isna()\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7438404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask]          # df[df.group.isna()]\n",
    "df.loc[mask, :]   # df.loc[df.group.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1aba6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7edb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e4ed44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd71946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734baab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ae9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f638dd05",
   "metadata": {},
   "source": [
    "### b. Replace the Null/Missing Values under the `group` Column\n",
    "- After detecting the NaN values, the next question is, what value we should write in the cells where we have Null/Missing values\n",
    "- Since this is a categorical column having datatype object (group A, group B, group C, ...), so let us replace it with th value inside the column having the maximum frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use value_counts() function which return a Series containing counts of unique values (in descending order)\n",
    "# with the most frequently-occurring element at first. It excludes NA values by default.\n",
    "df.group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c21ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of doing is use the mode() function on the column\n",
    "df.group.mode() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cf51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb606a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1dd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47299a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c578a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only those records under group column having Null values\n",
    "mask = df.group.isna()\n",
    "df.loc[mask, 'group']     # df.loc[(df.group.isna()), 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us replace these values with maximum occurring value in the `group` column\n",
    "df.loc[(df.group.isna()),'group'] = 'group C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69298cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97beea48",
   "metadata": {},
   "source": [
    ">Note that in the original dataframe Arifa group information was missing, and now it is `group C` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1d848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cda805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73650b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2219dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914cb3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a1eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "406a2755",
   "metadata": {},
   "source": [
    "## 5. Handle Missing values under a Numeric/Categorical Column using `fillna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b16b8",
   "metadata": {},
   "source": [
    "### a. Replace the Null/Missing Values under the math Column using `fillna()`\n",
    "- This is more recommended way of filling in the Null values within columns of your dataset rather than the use of the `loc` method.\n",
    "```\n",
    "object.fillna(value, method, inplace=True)\n",
    "```\n",
    "- The only required argument is either the `value`, with which we want to replace the missing values OR the `method` to be used to replace the missing values\n",
    "- Returns object with missing values filled or None if ``inplace=True``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe077e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us read the dataset again with NA values under math column\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ac82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d523b42b",
   "metadata": {},
   "source": [
    ">- Before proceeding, let us this time handle the string value `No Idea` under the math column while reading the csv file, instead of doing afterwards in the dataframe using the `replace()` method as we have done above.\n",
    ">- For this we will use the `na_values` argument to the `pd.read_csv()` method, to which you can pass a single value or a list of values to be replaced with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e132d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/group-marks.csv', na_values='No Idea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d746cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.math.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e30ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46464ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a58b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8541f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time instead of loc, use fillna() method with just two arguments\n",
    "# inplace=True parameter ensure that this happens in the original dataframe\n",
    "\n",
    "df.math.fillna(value=df.math.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60298853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df98ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600568d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6925bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c0bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2d725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "926ec32f",
   "metadata": {},
   "source": [
    "### b. Replace the Null/Missing Values under the `group` Column using `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad051b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us read the dataset again with NA values\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv', na_values='No Idea')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d9d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once again instead of loc,let us use fillna() method with just two arguments\n",
    "\n",
    "df.group.fillna('group C', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70222f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180f3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1fc12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52b88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca71132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4749b983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us fill the math, english and scholarship columns as well again\n",
    "df.math.fillna(df.math.mean(), inplace=True)\n",
    "df.english.fillna(df.english.mean(), inplace=True)\n",
    "df.scholarship.fillna(df.scholarship.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c214fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f536e66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac25fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd8a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19b4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd55f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e88d9dc",
   "metadata": {},
   "source": [
    "### c. Replace the Null/Missing Values under the` math` and `group` Column using `ffill` and `bfill` Arguments\n",
    "- In above examples, we have used the mean value in case of numeric column and mode value in case of a categorical column as the filling value to the `fillna()` method\n",
    "```\n",
    "object.fillna(value, method, inplace=True)\n",
    "```\n",
    "\n",
    "- We can pass `ffill` or `bfill` as method argument to the `ffillna()` method. This will replace the null values with other values from the DataFrame\n",
    "- `ffill` (Forward fill): It fills the NaN value with the previous value\n",
    "- `bfill` (Back fill): It fills the NaN value with the Next/Upcoming value\n",
    "\n",
    "<img align=\"right\" width=\"490\" height=\"100\"  src=\"images/bfill.png\"  >\n",
    "<img align=\"left\" width=\"490\" height=\"100\"  src=\"images/ffill.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ec42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us read the dataset again with NA values\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv', na_values='No Idea')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2edccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4dec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e2542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722da48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39248127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0748ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill or ffill attribute\n",
    "# If have NaN value, just carry forward the previous value\n",
    "# using ffill attribute, you can fill the NaN value with the previous value in that column\n",
    "df.fillna(method = 'ffill', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2496c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690fbba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255c451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ceb339a6",
   "metadata": {},
   "source": [
    ">Is it working fine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ea854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a8c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109195b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88669bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method = 'bfill', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca48c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ab2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26c608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1d4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b43190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a5191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef067a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518109c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7056aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0d137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "849f595d",
   "metadata": {},
   "source": [
    "## 6. Handle Repeating Values (for same information) under the `session` Column\n",
    "- If you observe the values under the `session` column, you can observe that it is a categorical column containing six different categories (as values).\n",
    "    - Notice that the categories `MORNING` and `MOR` are same\n",
    "    - Similarly, `AFTERNOON` and `AFT` are same\n",
    "    - Similarly, `EVENING` and `EVE` are same\n",
    "- This happens when you have collected data from different sources, where same information is written in different ways\n",
    "- So the `session` column has six different categories (as values) but should have only three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39378b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv' )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a11aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6266ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let use check out the counts of unique values inside the session Column\n",
    "df.session.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cef2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ccdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e160c362",
   "metadata": {},
   "source": [
    "###  Handle  the Repeating Values under the session Column using `map()`\n",
    "- To keep the data clean we will map all these values to only three categories to `MOR` , `AFT` and `EVE` using the map() function.\n",
    "```\n",
    "df.map(mapping, na_action=None)\n",
    "```\n",
    "- The `map()` method is used for substituting each value in a Series with another value, that may be derived from a `dict`. The `map()` method returns a series after performing the mapping\n",
    "- You can give `ignore` as second argument which will propagate NaN values, without passing them to the mapping correspondence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do this, let us create a new mapping (dictionary) \n",
    "dict1 = {\n",
    "    'MORNING' : 'MOR',\n",
    "    'MOR' : 'MOR',\n",
    "    'AFTERNOON' : 'AFT',\n",
    "    'AFT': 'AFT',\n",
    "    'EVENING' : 'EVE',\n",
    "    'EVE': 'EVE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns a series with the same index as caller, the original series remains unchanged. \n",
    "# So we have assigned the resulting series to `df.session` series\n",
    "df.session.map(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f18aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.session = df.session.map(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20810ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of new categories in the column session\n",
    "# Observe we have managed to properly manage the values inside the session column\n",
    "df.session.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us verify the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c452132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9e371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe2dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc04927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199eecab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092312dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0d90de5",
   "metadata": {},
   "source": [
    "## 7. Create a new Column by Modifying an Existing Column\n",
    "- We have a column scholarship in the dataset, which is in Pak Rupees\n",
    "- Suppose you want to have a new column which should represent the scholarship in US Dollars\n",
    "- For that we need to add a new column by dividing each value of scholarship with 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv' )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.scholarship.apply(lambda x: x/170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Scholarship_in_$'] = df.scholarship.apply(lambda x : x/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0d3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3980e271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598418a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfd24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160d2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88eea76d",
   "metadata": {},
   "source": [
    "## 8. Delete Rows Having NaN values using `df.dropna()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use dropna() method to drop all the rows, it it has any na value\n",
    "df1 = df.dropna()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56deee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a86d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Arguments to dropna()\n",
    "df2 = df.dropna(axis=0, how='any')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974e8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f2bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3c493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84548ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we set how='all` it means drop a row only if all of its values are NA\n",
    "df2 = df.dropna(axis=0, how='all')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be699f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198315a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d649d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784bdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c02954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of subset argument and pass it a list of columns based on whose values you want to drop a row\n",
    "df2 = df.dropna(axis=0, how='any', subset=['math'])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac27c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227cfb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cde1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f729f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of subset argument\n",
    "df2 = df.dropna(axis=0, how='any', subset=['session'])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb836d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bee23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3e6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having `how=all` and `subset=listofcolumnnames`, then it will \n",
    "# drop a row only if both the columns have a NA value in that row\n",
    "df2 = df.dropna(axis=0, how='all', subset=['math', 'session'])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70f2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cd943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be60310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02bf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c92332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we set the axis=1 and how=all, it means drop a column if all the  values under it is na\n",
    "df2 = df.dropna(axis=1, how='all')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dad962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfebb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0d47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581677fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we set the axis=1 and how=any, it means drop a column if any value under it is na\n",
    "df2 = df.dropna(axis=1, how='any')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a9d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e87838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d4f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4273e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30efa826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc62a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d527fdbe",
   "metadata": {},
   "source": [
    "## 9. Convert Categorical Variables into Numerical\n",
    "- Most of the machine learning algorithms do not take categorical variables so we need to convert them into numerical ones. \n",
    "- We can do this using Pandas function `pd.get_dummies()`, which will create a binary column for each of the categories. \n",
    "```\n",
    "pd.get_dummies(data, drop_first=False)\n",
    "```\n",
    "- Where, the only required argument is `data` which can be a dataframe or a series\n",
    "- The parameter drop_first : bool, default False Whether to get k-1 dummies out of k categorical levels by removing the first level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c50a3",
   "metadata": {},
   "source": [
    "### a. Convert all categorical variables into dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e83961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently we have 9 columns in the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17c444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aab871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categorical variables into dummy/indicator variables\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us view the datafreame, keep a note on the number of columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4ca5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Number of columns has gone to 1605 now\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94e433",
   "metadata": {},
   "source": [
    "- So we have 112 columns\n",
    "- Even though one-hot encoding is a good way to convert your categorical columns to numerical columns\n",
    "- But it adds a lot of dimensionality to your data, i.e., increase the number of columns\n",
    "- It also become difficult to deal with that much number of columns\n",
    "- This is a trade-off, which is handled by technique called dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4d4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56133b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeac152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf725cc0",
   "metadata": {},
   "source": [
    "### b. Perform One-Hot Encoding for Categorical Column `gender` Only\n",
    "- In our dataframe, the gender column is a categorical column having two values 'male' and 'female'\n",
    "- It will create a dummy binary columns.  \n",
    "- This is also known as `One Hot Encoding`. You will learn more encoding techniques in the data pre-processing module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f41e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('datasets/group-marks.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d288db42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058940b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert only gender variable into dummy/indicator variables\n",
    "df2 = pd.get_dummies(df1[['gender']])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f605b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we donot need two separate columns, so simply use the `drop_first` argument of get_dummies to handle this\n",
    "df2 = pd.get_dummies(df1[['gender']], drop_first=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31765384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will talk about join in the next session in detail.\n",
    "df3 = df1.join(df2['gender_male'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7f244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46456c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e1199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9b2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b61671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
